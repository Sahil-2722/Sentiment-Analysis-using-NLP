{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233285fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18358b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'subtheme_1', 'subtheme_2', 'Unnamed: 3', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
      "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
      "       'Unnamed: 14'],\n",
      "      dtype='object')\n",
      "                                                  review           Subtheme  \\\n",
      "0      Tires where delivered to the garage of my choi...     Garage service   \n",
      "0      Tires where delivered to the garage of my choi...  Selection process   \n",
      "0      Tires where delivered to the garage of my choi...    Fitting process   \n",
      "1      Easy Tyre Selection Process, Competitive Prici...     Garage service   \n",
      "1      Easy Tyre Selection Process, Competitive Prici...  Selection process   \n",
      "...                                                  ...                ...   \n",
      "10129  I ordered the tyre I needed on line, booked a ...              Price   \n",
      "10129  I ordered the tyre I needed on line, booked a ...    Fitting process   \n",
      "10130  Excellent service from point of order to fitti...     Garage service   \n",
      "10130  Excellent service from point of order to fitti...    Fitting process   \n",
      "10131  Seamless, well managed at both ends. I would r...                NaN   \n",
      "\n",
      "         Type Sentiment  \n",
      "0      aspect  positive  \n",
      "0      aspect  positive  \n",
      "0      aspect  positive  \n",
      "1      aspect  positive  \n",
      "1      aspect  positive  \n",
      "...       ...       ...  \n",
      "10129  aspect  positive  \n",
      "10129  aspect  positive  \n",
      "10130  aspect  positive  \n",
      "10130  aspect  positive  \n",
      "10131    None      None  \n",
      "\n",
      "[17179 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "column_names = [\n",
    "    'review', 'subtheme_1', 'subtheme_2', 'Unnamed: 3', 'Unnamed: 4', \n",
    "    'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', \n",
    "    'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('Evaluation-dataset.csv', names=column_names)\n",
    "print(data.columns)\n",
    "\n",
    "review_column = 'review'\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['cleaned_review'] = data[review_column].apply(preprocess_text)\n",
    "\n",
    "def identify_subthemes(text):\n",
    "    subthemes = []\n",
    "    if 'incorrect tyre' in text or 'missing tyre' in text:\n",
    "        subthemes.append(('Incorrect tyres sent', 'problem'))\n",
    "    if 'garage' in text or 'service' in text:\n",
    "        subthemes.append(('Garage service', 'aspect'))\n",
    "    if 'delay' in text or 'wait time' in text:\n",
    "        subthemes.append(('Wait time', 'aspect'))\n",
    "    if 'booking' in text or 'book' in text:\n",
    "        subthemes.append(('Ease of booking', 'aspect'))\n",
    "    if 'price' in text or 'cost' in text or 'value' in text:\n",
    "        subthemes.append(('Price', 'aspect'))\n",
    "    if 'selection' in text or 'choose' in text or 'choice' in text:\n",
    "        subthemes.append(('Selection process', 'aspect'))\n",
    "    if 'fitting' in text or 'install' in text or 'fit' in text:\n",
    "        subthemes.append(('Fitting process', 'aspect'))\n",
    "    return subthemes\n",
    "\n",
    "data['subthemes'] = data['cleaned_review'].apply(identify_subthemes)\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    score = analyzer.polarity_scores(text)\n",
    "    if score['compound'] >= 0.05:\n",
    "        return 'positive'\n",
    "    elif score['compound'] <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "def analyze_subthemes(row):\n",
    "    subthemes = row['subthemes']\n",
    "    sentiments = []\n",
    "    for subtheme, sub_type in subthemes:\n",
    "        sentiment = get_sentiment(row[review_column])\n",
    "        sentiments.append((subtheme, sub_type, sentiment))\n",
    "    return sentiments\n",
    "\n",
    "data['subtheme_sentiments'] = data.apply(analyze_subthemes, axis=1)\n",
    "\n",
    "exploded_data = data.explode('subtheme_sentiments')\n",
    "\n",
    "\n",
    "exploded_data[['Subtheme', 'Type', 'Sentiment']] = pd.DataFrame(exploded_data['subtheme_sentiments'].tolist(), index=exploded_data.index)\n",
    "\n",
    "exploded_data = exploded_data.drop(columns=['subtheme_sentiments', 'cleaned_review'])\n",
    "\n",
    "\n",
    "print(exploded_data[[review_column, 'Subtheme', 'Type', 'Sentiment']])\n",
    "\n",
    "exploded_data.to_csv('review_subtheme_sentiments_power_bi.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9943901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc3b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
